{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmicatka.cui.apluw.local/miniconda3/envs/neusis/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from MLP import *\n",
    "\n",
    "#from PIL import Image\n",
    "import cv2 as cv\n",
    "import time\n",
    "import random\n",
    "import string \n",
    "from pyhocon import ConfigFactory\n",
    "from models.fields import RenderingNetwork, SDFNetwork, SingleVarianceNetwork, NeRF\n",
    "from models.renderer import NeuSRenderer\n",
    "import trimesh\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from load_data import *\n",
    "import logging\n",
    "import argparse \n",
    "import datetime\n",
    "\n",
    "from math import ceil\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a function into recursive style to handle nested dict/list/tuple variables\n",
    "def make_recursive_func(func):\n",
    "    def wrapper(vars):\n",
    "        if isinstance(vars, list):\n",
    "            return [wrapper(x) for x in vars]\n",
    "        elif isinstance(vars, tuple):\n",
    "            return tuple([wrapper(x) for x in vars])\n",
    "        elif isinstance(vars, dict):\n",
    "            return {k: wrapper(v) for k, v in vars.items()}\n",
    "        else:\n",
    "            return func(vars)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "@make_recursive_func\n",
    "def tensor2float(vars):\n",
    "    if isinstance(vars, float):\n",
    "        return vars\n",
    "    elif isinstance(vars, torch.Tensor):\n",
    "        return vars.data.item()\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"invalid input type {} for tensor2float\".format(type(vars))\n",
    "        )\n",
    "    \n",
    "class Runner:\n",
    "    def __init__(self, conf, is_continue=False, write_config=True):\n",
    "        conf_path = conf\n",
    "        f = open(conf_path)\n",
    "        conf_text = f.read()\n",
    "        self.is_continue = is_continue\n",
    "        self.conf = ConfigFactory.parse_string(conf_text)\n",
    "        self.write_config = write_config\n",
    "\n",
    "    def set_params(self):\n",
    "        self.expID = self.conf.get_string('conf.expID') \n",
    "\n",
    "        dataset = self.conf.get_string('conf.dataset')\n",
    "        self.image_setkeyname =  self.conf.get_string('conf.image_setkeyname') \n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dataset = dataset\n",
    "\n",
    "        # Training parameters\n",
    "        self.end_iter = self.conf.get_int('train.end_iter')\n",
    "        self.N_rand = self.conf.get_int('train.num_select_pixels') #H*W \n",
    "        self.arc_n_samples = self.conf.get_int('train.arc_n_samples')\n",
    "        self.save_freq = self.conf.get_int('train.save_freq')\n",
    "        self.report_freq = self.conf.get_int('train.report_freq')\n",
    "        self.val_mesh_freq = self.conf.get_int('train.val_mesh_freq')\n",
    "        self.learning_rate = self.conf.get_float('train.learning_rate')\n",
    "        self.learning_rate_alpha = self.conf.get_float('train.learning_rate_alpha')\n",
    "        self.warm_up_end = self.conf.get_float('train.warm_up_end', default=0.0)\n",
    "        self.anneal_end = self.conf.get_float('train.anneal_end', default=0.0)\n",
    "        self.percent_select_true = self.conf.get_float('train.percent_select_true', default=0.5)\n",
    "        self.r_div = self.conf.get_bool('train.r_div')\n",
    "\n",
    "        # Weights\n",
    "        self.igr_weight = self.conf.get_float('train.igr_weight')\n",
    "        self.variation_reg_weight = self.conf.get_float('train.variation_reg_weight')\n",
    "        self.px_sample_min_weight = self.conf.get_float('train.px_sample_min_weight')\n",
    "\n",
    "        self.ray_n_samples = self.conf['model.neus_renderer']['n_samples']\n",
    "        self.base_exp_dir = './experiments/{}'.format(self.expID)\n",
    "        self.randomize_points = self.conf.get_float('train.randomize_points')\n",
    "        self.select_px_method = self.conf.get_string('train.select_px_method')\n",
    "        self.select_valid_px = self.conf.get_bool('train.select_valid_px')        \n",
    "        self.x_max = self.conf.get_float('mesh.x_max')\n",
    "        self.x_min = self.conf.get_float('mesh.x_min')\n",
    "        self.y_max = self.conf.get_float('mesh.y_max')\n",
    "        self.y_min = self.conf.get_float('mesh.y_min')\n",
    "        self.z_max = self.conf.get_float('mesh.z_max')\n",
    "        self.z_min = self.conf.get_float('mesh.z_min')\n",
    "        self.level_set = self.conf.get_float('mesh.level_set')\n",
    "\n",
    "        self.data = load_data(dataset)\n",
    "\n",
    "        self.H, self.W = self.data[self.image_setkeyname][0].shape\n",
    "\n",
    "        self.r_min = self.data[\"min_range\"]\n",
    "        self.r_max = self.data[\"max_range\"]\n",
    "        self.phi_min = -self.data[\"vfov\"]/2\n",
    "        self.phi_max = self.data[\"vfov\"]/2\n",
    "        self.vfov = self.data[\"vfov\"]\n",
    "        self.hfov = self.data[\"hfov\"]\n",
    "\n",
    "\n",
    "        self.cube_center = torch.Tensor([(self.x_max + self.x_min)/2, (self.y_max + self.y_min)/2, (self.z_max + self.z_min)/2])\n",
    "\n",
    "        self.timef = self.conf.get_bool('conf.timef')\n",
    "        self.end_iter = self.conf.get_int('train.end_iter')\n",
    "        self.start_iter = self.conf.get_int('train.start_iter')\n",
    "         \n",
    "        self.object_bbox_min = self.conf.get_list('mesh.object_bbox_min')\n",
    "        self.object_bbox_max = self.conf.get_list('mesh.object_bbox_max')\n",
    "\n",
    "        r_increments = []\n",
    "        self.sonar_resolution = (self.r_max-self.r_min)/self.H\n",
    "        for i in range(self.H):\n",
    "            r_increments.append(i*self.sonar_resolution + self.r_min)\n",
    "\n",
    "        self.r_increments = torch.FloatTensor(r_increments).to(self.device)\n",
    "\n",
    "        extrapath = './experiments/{}'.format(self.expID)\n",
    "        if not os.path.exists(extrapath):\n",
    "            os.makedirs(extrapath)\n",
    "\n",
    "        extrapath = './experiments/{}/checkpoints'.format(self.expID)\n",
    "        if not os.path.exists(extrapath):\n",
    "            os.makedirs(extrapath)\n",
    "\n",
    "        extrapath = './experiments/{}/model'.format(self.expID)\n",
    "        if not os.path.exists(extrapath):\n",
    "            os.makedirs(extrapath)\n",
    "\n",
    "        if self.write_config:\n",
    "            with open('./experiments/{}/config.json'.format(self.expID), 'w') as f:\n",
    "                json.dump(self.conf.__dict__, f, indent = 2)\n",
    "\n",
    "        # Create all image tensors beforehand to speed up process\n",
    "\n",
    "        self.i_train = np.arange(len(self.data[self.image_setkeyname]))\n",
    "\n",
    "        self.coords_all_ls = [(x, y) for x in np.arange(self.H) for y in np.arange(self.W)]\n",
    "        self.coords_all_set = set(self.coords_all_ls)\n",
    "\n",
    "        #self.coords_all = torch.from_numpy(np.array(self.coords_all_ls)).to(self.device)\n",
    "\n",
    "        self.del_coords = []\n",
    "        for y in np.arange(self.W):\n",
    "            tmp = [(x, y) for x in np.arange(0, self.ray_n_samples)]\n",
    "            self.del_coords.extend(tmp)\n",
    "\n",
    "        self.coords_all = list(self.coords_all_set - set(self.del_coords))\n",
    "        self.coords_all = torch.LongTensor(self.coords_all).to(self.device)\n",
    "\n",
    "        self.criterion = torch.nn.L1Loss(reduction='sum')\n",
    "        \n",
    "        self.model_list = []\n",
    "        self.writer = None\n",
    "\n",
    "        # Networks\n",
    "        params_to_train = []\n",
    "        self.sdf_network = SDFNetwork(**self.conf['model.sdf_network']).to(self.device)\n",
    "\n",
    "        self.deviation_network = SingleVarianceNetwork(**self.conf['model.variance_network']).to(self.device)\n",
    "        self.color_network = RenderingNetwork(**self.conf['model.rendering_network']).to(self.device)\n",
    "        params_to_train += list(self.sdf_network.parameters())\n",
    "        params_to_train += list(self.deviation_network.parameters())\n",
    "        params_to_train += list(self.color_network.parameters())\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(params_to_train, lr=self.learning_rate)\n",
    "\n",
    "\n",
    "        self.iter_step = 0\n",
    "        self.renderer = NeuSRenderer(self.sdf_network,\n",
    "                                    self.deviation_network,\n",
    "                                    self.color_network,\n",
    "                                    self.base_exp_dir,\n",
    "                                    self.expID,\n",
    "                                    **self.conf['model.neus_renderer'])  \n",
    "\n",
    "        latest_model_name = None\n",
    "        if self.is_continue:\n",
    "            model_list_raw = os.listdir(os.path.join(self.base_exp_dir, 'checkpoints'))\n",
    "            model_list = []\n",
    "            for model_name in model_list_raw:\n",
    "                if model_name[-3:] == 'pth': #and int(model_name[5:-4]) <= self.end_iter:\n",
    "                    model_list.append(model_name)\n",
    "            model_list.sort()\n",
    "            latest_model_name = model_list[-1]\n",
    "\n",
    "        if latest_model_name is not None:\n",
    "            logging.info('Find checkpoint: {}'.format(latest_model_name))\n",
    "            self.load_checkpoint(latest_model_name)\n",
    "\n",
    "        current_time_str = str(datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "        logdir = f'./checkpoints/{dataset}_{current_time_str}/'\n",
    "\n",
    "        if not os.path.isdir(logdir):\n",
    "                os.mkdir(logdir)\n",
    "\n",
    "        print(\"current time\", current_time_str)\n",
    "        print(\"creating new summary file\")\n",
    "        self.logger = SummaryWriter(logdir)\n",
    "          \n",
    "    def getRandomImgCoordsByPercentage(self, target):\n",
    "        true_coords = []\n",
    "        for y in np.arange(self.W):\n",
    "            col = target[:, y]\n",
    "            gt0 = col > 0\n",
    "            indTrue = np.where(gt0)[0]\n",
    "            if len(indTrue) > 0:\n",
    "                true_coords.extend([(x, y) for x in indTrue])\n",
    "\n",
    "        sampling_perc = int(self.percent_select_true*len(true_coords))\n",
    "        true_coords = random.sample(true_coords, sampling_perc)\n",
    "        true_coords = list(set(true_coords) - set(self.del_coords))\n",
    "        true_coords = torch.LongTensor(true_coords).to(self.device)\n",
    "        target = torch.Tensor(target).to(self.device)\n",
    "        if self.iter_step%len(self.data[self.image_setkeyname]) !=0:\n",
    "            N_rand = 0\n",
    "        else:\n",
    "            N_rand = self.N_rand\n",
    "        N_rand = self.N_rand\n",
    "        coords = select_coordinates(self.coords_all, target, N_rand, self.select_valid_px)\n",
    "        \n",
    "        coords = torch.cat((coords, true_coords), dim=0)\n",
    "            \n",
    "        return coords, target\n",
    "\n",
    "    def train(self):\n",
    "        loss_arr = []\n",
    "\n",
    "        for i in trange(self.start_iter, self.end_iter, len(self.data[self.image_setkeyname])):\n",
    "            i_train = np.arange(len(self.data[self.image_setkeyname]))\n",
    "            np.random.shuffle(i_train)\n",
    "            loss_total = 0\n",
    "            sum_intensity_loss = 0\n",
    "            sum_eikonal_loss = 0\n",
    "            sum_total_variational = 0\n",
    "            \n",
    "            for j in trange(0, len(i_train)):\n",
    "                img_i = i_train[j]\n",
    "                target = self.data[self.image_setkeyname][img_i]\n",
    "                \n",
    "                pose = self.data[\"sensor_poses\"][img_i]  \n",
    "                \n",
    "                if self.select_px_method == \"byprob\":\n",
    "                    coords, target = self.getRandomImgCoordsByProbability(target)\n",
    "                else:\n",
    "                    coords, target = self.getRandomImgCoordsByPercentage(target)\n",
    "\n",
    "                n_pixels = len(coords)\n",
    "                rays_d, dphi, r, rs, pts, dists = get_arcs(self.H, self.W, self.phi_min, self.phi_max, self.r_min, self.r_max,  torch.Tensor(pose), n_pixels,\n",
    "                                                        self.arc_n_samples, self.ray_n_samples, self.hfov, coords, self.r_increments, \n",
    "                                                        self.randomize_points, self.device, self.cube_center)\n",
    "\n",
    "                target_s = target[coords[:, 0], coords[:, 1]]\n",
    "\n",
    "                render_out = self.renderer.render_sonar(rays_d, pts, dists, n_pixels, \n",
    "                                                        self.arc_n_samples, self.ray_n_samples,\n",
    "                                                        cos_anneal_ratio=self.get_cos_anneal_ratio())\n",
    "                \n",
    "                intensityPointsOnArc = render_out[\"intensityPointsOnArc\"]\n",
    "\n",
    "                gradient_error = render_out['gradient_error'] #.reshape(n_pixels, self.arc_n_samples, -1)\n",
    "\n",
    "                eikonal_loss = gradient_error.sum()*(1/(self.arc_n_samples*self.ray_n_samples*n_pixels))\n",
    "\n",
    "                variation_regularization = render_out['variation_error']*(1/(self.arc_n_samples*self.ray_n_samples*n_pixels))\n",
    "\n",
    "                if self.r_div:\n",
    "                    intensity_fine = (torch.divide(intensityPointsOnArc, rs)*render_out[\"weights\"]).sum(dim=1) \n",
    "                else:\n",
    "                    intensity_fine = render_out['color_fine']\n",
    "\n",
    "                intensity_error = self.criterion(intensity_fine, target_s)*(1/n_pixels)\n",
    "                    \n",
    "                loss = intensity_error + eikonal_loss * self.igr_weight  + variation_regularization*self.variation_reg_weight\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    lossNG = intensity_error + eikonal_loss * self.igr_weight \n",
    "                    loss_total += lossNG.cpu().numpy().item()\n",
    "                    sum_intensity_loss += intensity_error.cpu().numpy().item()\n",
    "                    sum_eikonal_loss += eikonal_loss.cpu().numpy().item()\n",
    "                    sum_total_variational +=  variation_regularization.cpu().numpy().item()\n",
    "                \n",
    "                self.iter_step += 1\n",
    "                self.update_learning_rate()\n",
    "\n",
    "                del(target)\n",
    "                del(target_s)\n",
    "                del(rays_d)\n",
    "                del(pts)\n",
    "                del(dists)\n",
    "                del(render_out)\n",
    "                del(coords)\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                l = loss_total/len(i_train)\n",
    "                iL =  sum_intensity_loss/len(i_train)\n",
    "                eikL =  sum_eikonal_loss/len(i_train)\n",
    "                varL =  sum_total_variational/len(i_train)\n",
    "                loss_arr.append(l)\n",
    "\n",
    "            if i ==0 or i % self.save_freq == 0:\n",
    "                logging.info('iter:{} ********************* SAVING CHECKPOINT ****************'.format(self.optimizer.param_groups[0]['lr']))\n",
    "                self.save_checkpoint()\n",
    "\n",
    "            if i % self.report_freq == 0:\n",
    "                print(f\"iter:{self.iter_step:8>d} Loss={l} | intensity Loss={iL} | eikonal loss={eikL} | total variation loss = {varL} | lr={self.optimizer.param_groups[0]['lr']}\")\n",
    "                scalar_outputs = {\"loss\": l, \"eikonal_loss\": eikL, \"intensity_loss\": iL, \"variation_loss\": varL}\n",
    "                self.log_scalars('train', scalar_outputs, self.iter_step)\n",
    "\n",
    "            if i == 0 or i % self.val_mesh_freq == 0:\n",
    "                vertices, faces = self.validate_mesh(threshold = self.level_set)\n",
    "                vertices = np.expand_dims(vertices, 0)\n",
    "                faces = np.expand_dims(faces, 0)\n",
    "                self.logger.add_mesh(\"mesh_validate\", vertices, faces, global_step=self.iter_step)\n",
    "            \n",
    "    def save_checkpoint(self):\n",
    "        checkpoint = {\n",
    "            'sdf_network_fine': self.sdf_network.state_dict(),\n",
    "            'variance_network_fine': self.deviation_network.state_dict(),\n",
    "            'color_network_fine': self.color_network.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'iter_step': self.iter_step,\n",
    "        }\n",
    "\n",
    "        os.makedirs(os.path.join(self.base_exp_dir, 'checkpoints'), exist_ok=True)\n",
    "        torch.save(checkpoint, os.path.join(self.base_exp_dir, 'checkpoints', 'ckpt_{:0>6d}.pth'.format(self.iter_step)))\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_name):\n",
    "        checkpoint = torch.load(os.path.join(self.base_exp_dir, 'checkpoints', checkpoint_name), map_location=self.device)\n",
    "        self.sdf_network.load_state_dict(checkpoint['sdf_network_fine'])\n",
    "        self.deviation_network.load_state_dict(checkpoint['variance_network_fine'])\n",
    "        self.color_network.load_state_dict(checkpoint['color_network_fine'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        self.iter_step = checkpoint['iter_step']\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        if self.iter_step < self.warm_up_end:\n",
    "            learning_factor = self.iter_step / self.warm_up_end\n",
    "        else:\n",
    "            alpha = self.learning_rate_alpha\n",
    "            progress = (self.iter_step - self.warm_up_end) / (self.end_iter - self.warm_up_end)\n",
    "            learning_factor = (np.cos(np.pi * progress) + 1.0) * 0.5 * (1 - alpha) + alpha\n",
    "\n",
    "        for g in self.optimizer.param_groups:\n",
    "            g['lr'] = self.learning_rate * learning_factor\n",
    "\n",
    "    def get_cos_anneal_ratio(self):\n",
    "        if self.anneal_end == 0.0:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return np.min([1.0, self.iter_step / self.anneal_end])\n",
    "\n",
    "    def validate_mesh(self, world_space=False, resolution=64, threshold=0.0):\n",
    "        bound_min = torch.tensor(self.object_bbox_min, dtype=torch.float32)\n",
    "        bound_max = torch.tensor(self.object_bbox_max, dtype=torch.float32)\n",
    "\n",
    "        vertices, triangles =\\\n",
    "            self.renderer.extract_geometry(bound_min, bound_max, resolution=resolution, threshold=threshold)\n",
    "\n",
    "        os.makedirs(os.path.join(self.base_exp_dir, 'meshes'), exist_ok=True)\n",
    "\n",
    "        if world_space:\n",
    "            vertices = vertices * self.dataset.scale_mats_np[0][0, 0] + self.dataset.scale_mats_np[0][:3, 3][None]\n",
    "\n",
    "        mesh = trimesh.Trimesh(vertices, triangles)\n",
    "        mesh.export(os.path.join(self.base_exp_dir, 'meshes', '{:0>8d}.ply'.format(self.iter_step)))\n",
    "        return vertices, triangles\n",
    "\n",
    "    def log_scalars(self, mode, scalar_dict, global_step):\n",
    "        scalar_dict = tensor2float(scalar_dict)\n",
    "        for key, value in scalar_dict.items():\n",
    "            if not isinstance(value, (list, tuple)):\n",
    "                name = \"{}/{}\".format(mode, key)\n",
    "                self.logger.add_scalar(name, value, global_step)\n",
    "            else:\n",
    "                for idx in range(len(value)):\n",
    "                    name = \"{}/{}_{}\".format(mode, key, idx)\n",
    "                    self.logger.add_scalar(name, value[idx], global_step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time 20230403_105417\n",
      "creating new summary file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 19/988 [00:04<03:35,  4.50it/s]\n",
      "  0%|          | 0/304 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fb64593618e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_continue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-6d7e17b6c1ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintensity_error\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meikonal_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0migr_weight\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mvariation_regularization\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariation_reg_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neusis/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neusis/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "FORMAT = \"[%(filename)s:%(lineno)s - %(funcName)20s() ] %(message)s\"\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "logging.basicConfig(level=logging.DEBUG, format=FORMAT)\n",
    "\n",
    "conf = \"/home/mmicatka.cui.apluw.local/Documents/neusis/confs/14deg_planeFull.conf\"\n",
    "is_continue = False\n",
    "gpu=0\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "runner = Runner(conf, is_continue)\n",
    "runner.set_params()\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neusis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
